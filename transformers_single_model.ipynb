{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8779ed80-afb9-4d06-983d-0c9fd9d6ec39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T23:30:20.597670900Z",
     "start_time": "2025-03-03T23:30:20.596670700Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModel,AutoModelForMaskedLM\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from unidecode import unidecode\n",
    "import os\n",
    "import xgboost as xgb\n",
    "import json\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e836b3e0-589e-4494-bb4d-7ef3e4960d59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T23:30:20.598671300Z",
     "start_time": "2025-03-03T23:30:20.597670900Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "    torch.set_num_threads(1)\n",
    "\n",
    "    \n",
    "RANDOM_SEED = 42\n",
    "set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b723323f-19d4-4c4e-8a66-19b03a8536f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T23:30:20.610674500Z",
     "start_time": "2025-03-03T23:30:20.598671300Z"
    }
   },
   "outputs": [],
   "source": [
    "def pre_process(text):\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "\n",
    "    text = unidecode(text)\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    text = re.sub(r\"[^a-zA-Z0-9.,!?'\\s]\", \"\", text)\n",
    "\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a57a8b-a232-4fbd-be4d-cc9af68d86b2",
   "metadata": {},
   "source": [
    "# Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-03T23:30:20.599672Z"
    }
   },
   "outputs": [],
   "source": [
    "root = 'reviews/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e8c1d01-8fbd-4346-b7b6-c5a7283dc784",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-03T23:30:20.600672200Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.concat([pd.read_csv(root + f\"train-{i+1}.csv\") for i in range(7)], ignore_index=True)\n",
    "#test_data = pd.concat([pd.read_csv(root + f\"train-{i+1}.csv\") for i in [6,7]], ignore_index=True)\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b0699e1-006d-4c7d-9e0d-0493563b5656",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-03T23:30:20.602672600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emiel\\AppData\\Local\\Temp\\ipykernel_11380\\1899272772.py:2: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n",
      "C:\\Users\\emiel\\AppData\\Local\\Temp\\ipykernel_11380\\1899272772.py:2: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n"
     ]
    }
   ],
   "source": [
    "train_data['review_body'] = train_data['review_body'].apply(pre_process)\n",
    "test_data['review_body'] = test_data['review_body'].apply(pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1dca1e4-db0e-4b86-95dd-c664ab8409e1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-03T23:30:20.602672600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emiel\\AppData\\Local\\Temp\\ipykernel_11380\\1899272772.py:2: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n"
     ]
    }
   ],
   "source": [
    "validation_hidden_df = pd.read_csv(root + 'validation_hidden.csv')\n",
    "test_hidden_df = pd.read_csv(root + 'test_hidden.csv')\n",
    "\n",
    "validation_hidden_df['review_body'] = validation_hidden_df['review_body'].apply(pre_process)\n",
    "test_hidden_df['review_body'] = test_hidden_df['review_body'].apply(pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f4a700a-8ef9-459a-b5b7-3b0133cca89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "      <th>marketplace_id</th>\n",
       "      <th>product_category_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6641</th>\n",
       "      <td>5355</td>\n",
       "      <td>B0006GVK2A</td>\n",
       "      <td>460269617</td>\n",
       "      <td>Before Sunrise / Before Sunset [DVD]</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>excellent</td>\n",
       "      <td>2015-01-09</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3689</th>\n",
       "      <td>729</td>\n",
       "      <td>B000CJD3DU</td>\n",
       "      <td>325991288</td>\n",
       "      <td>Mr. &amp; Mrs. Smith</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Áctiớn-Klámáúk</td>\n",
       "      <td>ich habe den film im kino gesehen und wenn man...</td>\n",
       "      <td>2006-01-11</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>3525</td>\n",
       "      <td>B003UOVUR0</td>\n",
       "      <td>543062387</td>\n",
       "      <td>Eclipse - Bis(s) zum Abendrot (Fan Edition) [2...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Super Film !</td>\n",
       "      <td>der artikel ist quasi wie neu und funktioniert...</td>\n",
       "      <td>2011-11-08</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>4044</td>\n",
       "      <td>B002QY9RMA</td>\n",
       "      <td>913023308</td>\n",
       "      <td>I am...Sasha Fierce</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Ich liebe es!</td>\n",
       "      <td>ich mag dieses album sehr! wer beyonce mag, de...</td>\n",
       "      <td>2014-09-28</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>2245</td>\n",
       "      <td>B00D3NSDVO</td>\n",
       "      <td>307625827</td>\n",
       "      <td>I Am Pilgrim</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>best thriller i have read in years!</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>8542</td>\n",
       "      <td>B00HUMI5SK</td>\n",
       "      <td>276394270</td>\n",
       "      <td>The Wolf of Wall Street</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Kein guter Film</td>\n",
       "      <td>ich konnte mich mit dem film nicht wirklich an...</td>\n",
       "      <td>2014-10-13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>3116</td>\n",
       "      <td>B005V5WBFG</td>\n",
       "      <td>796588140</td>\n",
       "      <td>McAfee Mobile Security</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>c</td>\n",
       "      <td>2015-08-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>5015</td>\n",
       "      <td>B00B2FLDRQ</td>\n",
       "      <td>274604361</td>\n",
       "      <td>The Rosie Project: Don Tillman 1 (Don Tillman ...</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Funny and heartwarming</td>\n",
       "      <td>it's a little cheesy but really enjoyable. don...</td>\n",
       "      <td>2014-03-30</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>8870</td>\n",
       "      <td>B001E08UNE</td>\n",
       "      <td>825346055</td>\n",
       "      <td>Matrix [Blu-ray]</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Un film que l'on se plait à revoir</td>\n",
       "      <td>il n'est plus besoin de presenter ce film pour...</td>\n",
       "      <td>2009-03-22</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>11622</td>\n",
       "      <td>B00HSOV4Y2</td>\n",
       "      <td>919744947</td>\n",
       "      <td>All Is Lost</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Encore et tojours chronoposte</td>\n",
       "      <td>offert pour faire un cadeau, le film a fait mo...</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6769 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  product_id  product_parent  \\\n",
       "6641        5355  B0006GVK2A       460269617   \n",
       "3689         729  B000CJD3DU       325991288   \n",
       "3978        3525  B003UOVUR0       543062387   \n",
       "1583        4044  B002QY9RMA       913023308   \n",
       "1412        2245  B00D3NSDVO       307625827   \n",
       "...          ...         ...             ...   \n",
       "5734        8542  B00HUMI5SK       276394270   \n",
       "5191        3116  B005V5WBFG       796588140   \n",
       "5390        5015  B00B2FLDRQ       274604361   \n",
       "860         8870  B001E08UNE       825346055   \n",
       "7270       11622  B00HSOV4Y2       919744947   \n",
       "\n",
       "                                          product_title vine  \\\n",
       "6641               Before Sunrise / Before Sunset [DVD]    N   \n",
       "3689                                   Mr. & Mrs. Smith    N   \n",
       "3978  Eclipse - Bis(s) zum Abendrot (Fan Edition) [2...    N   \n",
       "1583                                I am...Sasha Fierce    N   \n",
       "1412                                       I Am Pilgrim    N   \n",
       "...                                                 ...  ...   \n",
       "5734                            The Wolf of Wall Street    N   \n",
       "5191                             McAfee Mobile Security    N   \n",
       "5390  The Rosie Project: Don Tillman 1 (Don Tillman ...    N   \n",
       "860                                    Matrix [Blu-ray]    N   \n",
       "7270                                        All Is Lost    N   \n",
       "\n",
       "     verified_purchase                     review_headline  \\\n",
       "6641                 Y                          Five Stars   \n",
       "3689                 Y                      Áctiớn-Klámáúk   \n",
       "3978                 N                        Super Film !   \n",
       "1583                 Y                       Ich liebe es!   \n",
       "1412                 Y                          Four Stars   \n",
       "...                ...                                 ...   \n",
       "5734                 Y                     Kein guter Film   \n",
       "5191                 Y                          Five Stars   \n",
       "5390                 Y              Funny and heartwarming   \n",
       "860                  Y  Un film que l'on se plait à revoir   \n",
       "7270                 N       Encore et tojours chronoposte   \n",
       "\n",
       "                                            review_body review_date  \\\n",
       "6641                                          excellent  2015-01-09   \n",
       "3689  ich habe den film im kino gesehen und wenn man...  2006-01-11   \n",
       "3978  der artikel ist quasi wie neu und funktioniert...  2011-11-08   \n",
       "1583  ich mag dieses album sehr! wer beyonce mag, de...  2014-09-28   \n",
       "1412                best thriller i have read in years!  2015-04-01   \n",
       "...                                                 ...         ...   \n",
       "5734  ich konnte mich mit dem film nicht wirklich an...  2014-10-13   \n",
       "5191                                                  c  2015-08-05   \n",
       "5390  it's a little cheesy but really enjoyable. don...  2014-03-30   \n",
       "860   il n'est plus besoin de presenter ce film pour...  2009-03-22   \n",
       "7270  offert pour faire un cadeau, le film a fait mo...  2015-07-01   \n",
       "\n",
       "      marketplace_id  product_category_id  label  \n",
       "6641               1                    3  False  \n",
       "3689               0                    3   True  \n",
       "3978               0                    3  False  \n",
       "1583               0                    6  False  \n",
       "1412               1                    4  False  \n",
       "...              ...                  ...    ...  \n",
       "5734               0                    3   True  \n",
       "5191               1                    1  False  \n",
       "5390               1                   10  False  \n",
       "860                2                    3   True  \n",
       "7270               2                    3  False  \n",
       "\n",
       "[6769 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b40453b-bead-464a-8675-970836275b11",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-03T23:30:20.605673300Z"
    }
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=512):\n",
    "\n",
    "        with open(root + \"category.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "            data = json.load(file)\n",
    "        df['category_name'] = df['product_category_id'].apply(lambda x: {d['id']:d['name'].replace(\"_\",' ').lower() for d in data}[x])\n",
    "\n",
    "        \n",
    "        texts = [\n",
    "        str(df.category_name.tolist()[i]) + ' ' + \n",
    "        str(df.review_headline.tolist()[i]) + ' ' + \n",
    "        str(df.category_name.tolist()[i]) + ' ' + \n",
    "        (\"vine \" if df.vine.tolist()[i] == 'Y' else '') + \n",
    "        (\"verified \" if df.verified_purchase.tolist()[i] == 'Y' else '') +\n",
    "        str(df.review_body.tolist()[i])\n",
    "        for i in range(len(df))\n",
    "        ]\n",
    "\n",
    "        \n",
    "        self.encodings = tokenizer(\n",
    "            texts, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        if 'label' in df.columns.tolist():\n",
    "            self.labels = torch.tensor(df.label.tolist(), dtype=torch.float)\n",
    "        else:\n",
    "            self.labels = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            \"input_ids\": self.encodings[\"input_ids\"][idx],\n",
    "            \"attention_mask\": self.encodings[\"attention_mask\"][idx]\n",
    "        }\n",
    "        if self.labels is not None:\n",
    "            item[\"label\"] = self.labels[idx]\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6384ecd3-ae66-48d7-96fe-44555e36df7e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-03T23:30:20.606673400Z"
    }
   },
   "outputs": [],
   "source": [
    "class TransformerForBinaryClassification(nn.Module):\n",
    "    def __init__(self, pretrained_model_name):\n",
    "        super(TransformerForBinaryClassification, self).__init__()\n",
    "        self.transformer = AutoModel.from_pretrained(pretrained_model_name)\n",
    "        self.hidden_size = self.transformer.config.hidden_size\n",
    "        self.text_classifier = nn.Linear(self.hidden_size, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        outputs = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        if hasattr(outputs, \"pooler_output\") and outputs.pooler_output is not None:\n",
    "            pooled_output = outputs.pooler_output\n",
    "        else:\n",
    "            hidden_states = outputs.last_hidden_state\n",
    "            pooled_output = (hidden_states * attention_mask.unsqueeze(-1)).sum(1) / attention_mask.sum(1, keepdim=True)\n",
    "\n",
    "        logits = self.text_classifier(pooled_output)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c98244d2-e9a9-4dbc-b3da-c5fa1c87041e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-03T23:30:20.606673400Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device).float() \n",
    "\n",
    "            logits = model(input_ids, attention_mask).view(-1) \n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            predictions = torch.sigmoid(logits)\n",
    "            predicted_labels = (predictions > 0.5).float()\n",
    "            correct += (predicted_labels == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518c8900-7deb-43b9-a941-28b3cd401c1f",
   "metadata": {},
   "source": [
    "# Finetune the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "721e8d5b-ddb8-4605-8a51-028a8af9fb9f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-03T23:30:20.608674400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100: Train Loss = 0.551, Train Accuracy = 0.703\n",
      "Step 100: Test Loss = 0.567, Test Accuracy = 0.709\n",
      "Step 200: Train Loss = 0.573, Train Accuracy = 0.682\n",
      "Step 200: Test Loss = 0.552, Test Accuracy = 0.709\n",
      "Step 300: Train Loss = 0.577, Train Accuracy = 0.696\n",
      "Step 300: Test Loss = 0.545, Test Accuracy = 0.729\n",
      "Step 400: Train Loss = 0.58, Train Accuracy = 0.691\n",
      "Step 400: Test Loss = 0.562, Test Accuracy = 0.718\n",
      "Step 500: Train Loss = 0.549, Train Accuracy = 0.718\n",
      "Step 500: Test Loss = 0.542, Test Accuracy = 0.725\n",
      "Step 600: Train Loss = 0.555, Train Accuracy = 0.715\n",
      "Step 600: Test Loss = 0.553, Test Accuracy = 0.722\n",
      "Step 700: Train Loss = 0.554, Train Accuracy = 0.71\n",
      "Step 700: Test Loss = 0.538, Test Accuracy = 0.729\n",
      "Step 800: Train Loss = 0.552, Train Accuracy = 0.718\n",
      "Step 800: Test Loss = 0.554, Test Accuracy = 0.708\n",
      "Step 900: Train Loss = 0.549, Train Accuracy = 0.721\n",
      "Step 900: Test Loss = 0.54, Test Accuracy = 0.723\n",
      "Step 1000: Train Loss = 0.523, Train Accuracy = 0.743\n",
      "Step 1000: Test Loss = 0.535, Test Accuracy = 0.729\n",
      "Step 1100: Train Loss = 0.483, Train Accuracy = 0.761\n",
      "Step 1100: Test Loss = 0.536, Test Accuracy = 0.73\n",
      "Step 1200: Train Loss = 0.524, Train Accuracy = 0.754\n",
      "Step 1200: Test Loss = 0.542, Test Accuracy = 0.732\n",
      "Step 1300: Train Loss = 0.545, Train Accuracy = 0.716\n",
      "Step 1300: Test Loss = 0.536, Test Accuracy = 0.732\n",
      "Step 1400: Train Loss = 0.538, Train Accuracy = 0.711\n",
      "Step 1400: Test Loss = 0.537, Test Accuracy = 0.727\n",
      "Step 1500: Train Loss = 0.514, Train Accuracy = 0.734\n",
      "Step 1500: Test Loss = 0.548, Test Accuracy = 0.714\n",
      "Step 1600: Train Loss = 0.513, Train Accuracy = 0.748\n",
      "Step 1600: Test Loss = 0.536, Test Accuracy = 0.735\n",
      "Step 1700: Train Loss = 0.515, Train Accuracy = 0.768\n",
      "Step 1700: Test Loss = 0.561, Test Accuracy = 0.714\n",
      "Step 1800: Train Loss = 0.464, Train Accuracy = 0.781\n",
      "Step 1800: Test Loss = 0.55, Test Accuracy = 0.714\n",
      "Step 1900: Train Loss = 0.445, Train Accuracy = 0.789\n",
      "Step 1900: Test Loss = 0.566, Test Accuracy = 0.716\n",
      "Step 2000: Train Loss = 0.432, Train Accuracy = 0.791\n",
      "Step 2000: Test Loss = 0.579, Test Accuracy = 0.725\n",
      "Step 2100: Train Loss = 0.474, Train Accuracy = 0.789\n",
      "Step 2100: Test Loss = 0.596, Test Accuracy = 0.711\n",
      "Step 2200: Train Loss = 0.485, Train Accuracy = 0.78\n",
      "Step 2200: Test Loss = 0.576, Test Accuracy = 0.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_name = \"distilbert/distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = TransformerForBinaryClassification(model_name)\n",
    "\n",
    "train_dataset = TextDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "test_dataset = TextDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "max_steps = 10_000  \n",
    "best_test_accuracy = 0.0\n",
    "best_model_path = \"models/best_model.pth\"\n",
    "\n",
    "step = 0\n",
    "total_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "model.train()\n",
    "train_iterator = iter(train_loader)  \n",
    "\n",
    "while step < max_steps:\n",
    "    try:\n",
    "        batch = next(train_iterator)  \n",
    "    except StopIteration:\n",
    "        train_iterator = iter(train_loader)  \n",
    "        batch = next(train_iterator)\n",
    "\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"label\"].to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    logits = model(input_ids, attention_mask)\n",
    "\n",
    "    loss = criterion(logits.view(-1), labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss += loss.item()\n",
    "\n",
    "    predictions = torch.sigmoid(logits).view(-1)\n",
    "    predicted_labels = (predictions > 0.5).float()\n",
    "    correct += (predicted_labels == labels).sum().item()\n",
    "    total += labels.size(0)\n",
    "\n",
    "    step += 1\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        train_loss = total_loss / 100\n",
    "        train_accuracy = correct / total\n",
    "        print(f\"Step {step}: Train Loss = {round(train_loss, 3)}, Train Accuracy = {round(train_accuracy, 3)}\")\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        test_loss, test_accuracy = evaluate(model, test_loader, criterion, device)\n",
    "        print(f\"Step {step}: Test Loss = {round(test_loss,3)}, Test Accuracy = {round(test_accuracy,3)}\")\n",
    "\n",
    "        torch.save(model.state_dict(), f\"models/bert_step_{step}.pth\")\n",
    "\n",
    "        if test_accuracy > best_test_accuracy:\n",
    "            best_test_accuracy = test_accuracy\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b3d237-3914-4eff-a27a-ce32efe66c36",
   "metadata": {},
   "source": [
    "# Generate the files for online submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d6234a8-d42b-4250-95c2-2c7496da3f87",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-03T23:30:20.609674300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emiel\\AppData\\Local\\Temp\\ipykernel_11380\\1036872741.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n",
      "Processing validation_hidden.csv: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:05<00:00, 28.08it/s]\n",
      "Processing test_hidden.csv: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 143/143 [00:05<00:00, 27.86it/s]\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "def generate_predictions_csv(df, filename, model, tokenizer, device):\n",
    "    dataset = TextDataset(df, tokenizer)\n",
    "    dataloader = DataLoader(dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=f\"Processing {filename}\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            probs = torch.sigmoid(logits).view(-1)\n",
    "            preds = (probs > 0.5).tolist()\n",
    "\n",
    "            predictions.extend(preds)\n",
    "\n",
    "    df_predictions = pd.DataFrame(predictions) \n",
    "    df_predictions.to_csv(filename, index=False, header=False)\n",
    "\n",
    "generate_predictions_csv(validation_hidden_df, \"validation_hidden.csv\", model, tokenizer, device)\n",
    "generate_predictions_csv(test_hidden_df, \"test_hidden.csv\", model, tokenizer, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b53ff5-51db-46c3-b055-d026bea4af21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
